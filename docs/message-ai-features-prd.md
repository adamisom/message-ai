# Product Requirements Document: Message AI - AI Features MVP

**Document Version:** 1.0  
**Last Updated:** October 22, 2025  
**Author:** Product Team  
**Status:** Ready for Implementation

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Product Overview](#product-overview)
3. [Technical Architecture](#technical-architecture)
4. [AI Feature Specifications](#ai-feature-specifications)
5. [Implementation Details](#implementation-details)
6. [Performance Requirements](#performance-requirements)
7. [Security & Privacy](#security--privacy)
8. [Testing Strategy](#testing-strategy)
9. [Success Metrics](#success-metrics)
10. [Future Enhancements](#future-enhancements)

---

## Executive Summary

### Purpose
This PRD defines the MVP implementation of AI-powered features for Message AI, a React Native messaging application. The goal is to enhance user productivity through intelligent message analysis while maintaining the application's core focus on speed and real-time performance.

### Scope
**MVP Features (Phase 1):**
- Thread Summarization
- Action Item Extraction
- Smart Search
- Priority Message Detection
- Decision Tracking

**Out of Scope for MVP:**
- Streaming responses for summarization
- Progressive loading for search results
- Multi-language support
- Voice message transcription
- Sentiment analysis

### Key Principles
1. **Speed First:** AI features must not degrade core messaging performance
2. **Simple UX:** Loading states with clear progress indicators
3. **Privacy:** All AI processing respects conversation permissions
4. **Pragmatic:** Focus on high-value features that users will actually use

---

## Product Overview

### Current Application State

**Platform:** React Native + Expo Framework  
**Backend:** Firebase (Auth + Firestore)  
**Current Features:**
- One-on-one and group chats
- Real-time message delivery
- Read receipts and unread indicators
- Online status indicators
- Push notifications
- Message persistence
- Optimistic UI updates

### Target Users
Mobile messaging users who need to:
- Quickly catch up on lengthy conversations
- Track commitments and action items
- Find specific information in message history
- Identify urgent messages requiring attention
- Track decisions made in group discussions

---

## Technical Architecture

### Stack Overview

**Frontend:**
- React Native (Expo)
- Firebase Web SDK (Authentication)
- Firestore SDK (Data operations)

**Backend:**
- Firebase Cloud Functions (Node.js runtime)
- Vercel AI SDK (AI orchestration)
- Anthropic Claude Sonnet 4 (LLM provider)
- Pinecone (Vector database for embeddings)

**AI Pipeline Architecture:**
```
[React Native App] â†’ [Firebase Cloud Functions] â†’ [Vercel AI SDK] â†’ [Claude API]
                                                â†“
                                          [Pinecone Vector DB]
                                                â†“
                                          [Firestore Cache]
```

### Firestore Data Structure

#### Collections Schema

**`/users/{uid}`**
```typescript
{
  uid: string,              // Firebase Auth UID
  email: string,            // Normalized lowercase email
  displayName: string,      // User-chosen display name
  isOnline: boolean,        // Online status
  lastSeenAt: timestamp,    // Last activity
  createdAt: timestamp,
  updatedAt: timestamp
}
```

**`/conversations/{conversationId}`**
```typescript
{
  type: 'direct' | 'group',
  participants: string[],    // Array of UIDs
  participantDetails: {      // Denormalized user info
    [uid]: {
      displayName: string,
      email: string
    }
  },
  lastMessage: string | null,        // Truncated to 100 chars
  lastMessageAt: timestamp | null,
  lastRead: { [uid]: messageId },    // Last message read per user
  lastReadAt: { [uid]: timestamp },  // Last read timestamp per user
  createdAt: timestamp,
  
  // Group-specific fields
  name?: string,
  creatorId?: string
}
```

**`/conversations/{conversationId}/messages/{messageId}`**
```typescript
{
  text: string,
  senderId: string,          // UID of sender
  senderName: string,        // Denormalized for display
  participants: string[],    // Denormalized for security rules
  createdAt: timestamp,      // Server timestamp
  status?: 'sending' | 'sent' | 'failed' | 'queued'  // Client-side only
}
```

**Conversation ID Patterns:**
- 1-on-1 chats: Deterministic ID using sorted UIDs â†’ `[uid1, uid2].sort().join('_')`
- Group chats: Auto-generated Firestore document ID

#### New Collections for AI Features

**`/conversations/{conversationId}/ai_summaries/{summaryId}`**
```typescript
{
  summary: string,              // Generated summary text
  keyPoints: string[],          // Array of key discussion points
  messageCount: number,         // Number of messages summarized
  startMessageId: string,       // First message in range
  endMessageId: string,         // Last message in range
  startTimestamp: timestamp,    // Start of summarized period
  endTimestamp: timestamp,      // End of summarized period
  generatedAt: timestamp,       // When summary was created
  generatedBy: string,          // UID of user who requested
  model: string                 // AI model used (e.g., "claude-sonnet-4")
}
```

**`/conversations/{conversationId}/ai_action_items/{itemId}`**
```typescript
{
  text: string,                 // Action item description
  assignee?: string,            // UID if assignee mentioned
  assigneeName?: string,        // Display name of assignee
  dueDate?: timestamp,          // Extracted due date if mentioned
  sourceMessageId: string,      // Message where item was identified
  sourceMessageText: string,    // Original message text
  priority: 'high' | 'medium' | 'low',
  status: 'pending' | 'completed',
  extractedAt: timestamp,       // When item was extracted
  completedAt?: timestamp
}
```

**`/conversations/{conversationId}/ai_decisions/{decisionId}`**
```typescript
{
  decision: string,             // The decision that was made
  context: string,              // Supporting context
  participants: string[],       // UIDs who agreed/participated
  sourceMessageIds: string[],   // Messages that led to decision
  decidedAt: timestamp,         // When decision was made
  extractedAt: timestamp        // When AI extracted it
}
```

**`/message_embeddings/{messageId}`** (Pinecone metadata mirrored in Firestore)
```typescript
{
  messageId: string,
  conversationId: string,
  text: string,
  embedding: number[],          // 1536-dim vector (text-embedding-3-small)
  senderId: string,
  senderName: string,
  createdAt: timestamp,
  indexedAt: timestamp
}
```

### RAG Pipeline Architecture

**Embedding Strategy:**
- **Model:** OpenAI `text-embedding-3-small` (1536 dimensions)
- **Trigger:** Real-time as messages are sent (Cloud Function)
- **Storage:** Pinecone vector database with Firestore metadata backup
- **Context Window:** Last 500 messages per conversation (expandable)

**Query Patterns:**

1. **Full Conversation Context** (for summarization, action items, decisions):
```javascript
// Get conversation metadata
const conversationDoc = await getDoc(doc(db, 'conversations', conversationId));

// Get messages in time range
const messagesQuery = query(
  collection(db, 'conversations', conversationId, 'messages'),
  orderBy('createdAt', 'asc'),
  where('createdAt', '>=', startTime),
  where('createdAt', '<=', endTime),
  limit(500)
);
```

2. **Semantic Search** (for Smart Search feature):
```javascript
// User query â†’ embedding
const queryEmbedding = await generateEmbedding(userQuery);

// Pinecone vector search
const searchResults = await pinecone.query({
  vector: queryEmbedding,
  filter: { 
    conversationId: conversationId,
    participants: { $in: [userId] }  // Security filter
  },
  topK: 10,
  includeMetadata: true
});

// Fetch full messages from Firestore
const messageIds = searchResults.matches.map(m => m.id);
const messages = await fetchMessagesByIds(conversationId, messageIds);
```

3. **Collection Group Query** (for cross-conversation search):
```javascript
// Note: Requires composite index in Firestore
const allMessagesQuery = query(
  collectionGroup(db, 'messages'),
  where('participants', 'array-contains', userId),
  orderBy('createdAt', 'desc'),
  limit(1000)
);
```

---

## AI Feature Specifications

### Feature 1: Thread Summarization

**User Story:**  
*"As a user, I want to quickly understand what happened in a long conversation without reading every message, so I can catch up efficiently."*

**Functionality:**
- Summarize the last N messages in a conversation (user-selectable: 25, 50, 100, all)
- Extract key discussion points as bullet points
- Show time range covered by the summary
- Cache summaries to avoid redundant processing

**UI/UX:**
- **Entry Point:** "Summarize Thread" button in conversation header
- **Loading State:** Modal with spinner and "Analyzing X messages..." text
- **Display:** Full-screen modal with:
  - Summary paragraph (3-5 sentences)
  - Key points (3-7 bullet points)
  - Time range covered
  - Message count
  - "Close" and "Share Summary" buttons

**Technical Implementation:**

*Cloud Function: `generateThreadSummary`*

```typescript
// Input parameters
interface SummarizeRequest {
  conversationId: string;
  userId: string;
  messageCount: number;  // 25, 50, 100, or -1 for all
}

// Processing flow
1. Validate user has access to conversation (check participants array)
2. Query last N messages from Firestore (ordered by createdAt)
3. Check if cached summary exists and is recent (< 1 hour old)
4. If no cache, construct prompt for Claude:
   - Include conversation type (1-on-1 vs group)
   - Include participant names
   - Include all messages with timestamps and sender names
5. Send to Claude API with structured output request
6. Store summary in Firestore (/ai_summaries subcollection)
7. Return summary to client

// Claude prompt structure
const prompt = `
You are summarizing a ${conversationType} conversation with ${participantCount} participants.
Participants: ${participantNames}

Messages (${messageCount} total, from ${startTime} to ${endTime}):
${formattedMessages}

Provide a summary in the following JSON format:
{
  "summary": "3-5 sentence overview of the conversation",
  "keyPoints": ["point 1", "point 2", "point 3"]
}

Focus on: main topics discussed, important decisions, action items, and key information shared.
`;
```

**Performance Targets:**
- Response time: 3-5 seconds for 100 messages
- Cache hit rate: >50% for frequently accessed threads
- Cost per summary: <$0.05

**Error Handling:**
- Network timeout: Show "Summary failed, please try again"
- Invalid conversation: Show "You don't have access to this conversation"
- API rate limit: Show "Too many requests, please wait a moment"

---

### Feature 2: Action Item Extraction

**User Story:**  
*"As a user, I want to see all action items and tasks mentioned in a conversation, so I don't forget commitments."*

**Functionality:**
- Automatically identify action items from messages
- Extract assignee if mentioned (e.g., "@John will handle this")
- Extract due dates if mentioned (e.g., "by Friday", "next week")
- Mark items as completed
- Show all action items for a conversation in one view

**UI/UX:**
- **Entry Point:** "Action Items" tab in conversation details
- **Loading State:** Spinner with "Scanning for action items..."
- **Display:** List view with:
  - Checkbox for completion status
  - Action item text
  - Assignee (if identified)
  - Due date (if mentioned)
  - Source message link (tap to jump to message)
  - Priority indicator (high/medium/low)

**Technical Implementation:**

*Cloud Function: `extractActionItems`*

```typescript
interface ActionItemRequest {
  conversationId: string;
  userId: string;
  messageRange?: { start: timestamp, end: timestamp };  // Optional range
}

// Processing flow
1. Validate user access
2. Query messages (last 100 by default, or specified range)
3. Check for cached action items (< 24 hours old)
4. Send messages to Claude with extraction prompt
5. Parse structured JSON response
6. Store in /ai_action_items subcollection
7. Return action items to client

// Claude prompt
const prompt = `
Extract action items from this conversation. An action item is a task, commitment, or to-do mentioned by any participant.

Messages:
${formattedMessages}

Return JSON array:
[
  {
    "text": "Description of the action item",
    "assignee": "Name of person responsible (if mentioned)",
    "dueDate": "ISO timestamp (if mentioned, otherwise null)",
    "priority": "high|medium|low",
    "sourceMessageId": "ID of message containing this item"
  }
]

Rules:
- Only extract clear, actionable items
- High priority: uses urgent language, has near deadline
- Medium priority: standard tasks with timeframes
- Low priority: suggestions or optional items
`;
```

**Performance Targets:**
- Response time: 2-4 seconds for 100 messages
- Accuracy: >85% precision on identifying actual action items
- False positive rate: <20%

**Edge Cases:**
- Completed items mentioned in messages: Mark with strikethrough
- Duplicate items: Deduplicate based on semantic similarity
- Ambiguous assignees: Leave assignee field empty

---

### Feature 3: Smart Search

**User Story:**  
*"As a user, I want to search for messages using natural language and concepts, not just exact keywords, so I can find relevant information even when I don't remember exact wording."*

**Functionality:**
- Semantic search across conversation history
- Search within current conversation or across all conversations
- Rank results by relevance
- Show context around matched messages

**UI/UX:**
- **Entry Point:** Search icon in conversation header or main screen
- **Loading State:** "Searching..." with spinner (800ms for 10 results)
- **Display:** List of results with:
  - Message preview (with search context highlighted)
  - Sender name and avatar
  - Timestamp
  - Conversation name (for cross-conversation search)
  - Tap to jump to message in full context

**Technical Implementation:**

*Cloud Function: `semanticSearch`*

```typescript
interface SearchRequest {
  query: string;
  userId: string;
  conversationId?: string;  // Optional: search within specific conversation
  limit: number;            // Default 10
}

// Processing flow
1. Generate embedding for search query using text-embedding-3-small
2. Query Pinecone with:
   - Query vector
   - Filter: user in participants array (security)
   - Filter: conversationId if specified
   - TopK: requested limit
3. Fetch full message documents from Firestore using returned message IDs
4. Return results with relevance scores

// Pinecone query
const results = await pineconeIndex.query({
  vector: queryEmbedding,  // 1536-dim vector
  filter: { 
    participants: { $in: [userId] },
    ...(conversationId && { conversationId })
  },
  topK: limit,
  includeMetadata: true
});
```

**Embedding Pipeline (Real-time):**

*Cloud Function: `embedMessage` (triggered on message creation)*

```typescript
// Firestore trigger
exports.embedMessage = functions.firestore
  .document('conversations/{conversationId}/messages/{messageId}')
  .onCreate(async (snap, context) => {
    const message = snap.data();
    
    // Generate embedding
    const embedding = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: message.text
    });
    
    // Store in Pinecone
    await pineconeIndex.upsert([{
      id: context.params.messageId,
      values: embedding.data[0].embedding,
      metadata: {
        conversationId: context.params.conversationId,
        text: message.text,
        senderId: message.senderId,
        senderName: message.senderName,
        participants: message.participants,
        createdAt: message.createdAt.toMillis()
      }
    }]);
    
    // Optional: Mirror in Firestore for backup
    await admin.firestore()
      .collection('message_embeddings')
      .doc(context.params.messageId)
      .set({
        messageId: context.params.messageId,
        conversationId: context.params.conversationId,
        indexedAt: admin.firestore.FieldValue.serverTimestamp()
      });
  });
```

**Performance Targets:**
- Embedding generation: <200ms per message
- Search query time: <500ms for embedding + search
- Total search time: <800ms for 10 results (including Firestore fetches)

**Search Quality Metrics:**
- Relevance: Top result relevant >80% of the time
- Recall: Finds target message in top 10 results >90% of the time

---

### Feature 4: Priority Message Detection

**User Story:**  
*"As a user, I want to be notified about urgent messages that need immediate attention, so I don't miss important information."*

**Functionality:**
- Analyze incoming messages for urgency indicators
- Flag messages as high, medium, or low priority
- Show priority badge on message
- Send enhanced push notification for high-priority messages

**UI/UX:**
- **Entry Point:** Automatic, runs on all incoming messages
- **Display:** 
  - Priority badge on message (ðŸ”´ High, ðŸŸ¡ Medium)
  - No badge for low priority (default)
  - Push notification includes priority level for high-priority messages

**Technical Implementation:**

*Cloud Function: `detectPriority` (triggered on message creation)*

```typescript
// Firestore trigger
exports.detectPriority = functions.firestore
  .document('conversations/{conversationId}/messages/{messageId}')
  .onCreate(async (snap, context) => {
    const message = snap.data();
    
    // Quick heuristic check first (avoid API calls for obvious low-priority)
    const quickCheck = quickPriorityCheck(message.text);
    if (quickCheck === 'low') {
      return null;  // Skip AI analysis for clearly low-priority
    }
    
    // Send to Claude for priority analysis
    const priority = await analyzeMessagePriority(message.text);
    
    // Update message document
    if (priority !== 'low') {
      await snap.ref.update({ priority });
      
      // Send enhanced push notification for high priority
      if (priority === 'high') {
        await sendPriorityNotification(message, priority);
      }
    }
  });

// Quick heuristic check (avoids AI cost for obvious cases)
function quickPriorityCheck(text: string): 'low' | 'unknown' {
  const lowPriorityPatterns = [
    /^(ok|okay|sure|thanks|lol|haha|ðŸ‘|ðŸ˜Š)/i,
    /^(see you|bye|good ?night|good morning)/i
  ];
  
  const urgentKeywords = [
    'urgent', 'asap', 'immediately', 'emergency', 'critical',
    'deadline', 'important', 'need now', 'right away'
  ];
  
  if (lowPriorityPatterns.some(pattern => pattern.test(text))) {
    return 'low';
  }
  
  if (urgentKeywords.some(keyword => text.toLowerCase().includes(keyword))) {
    return 'unknown';  // Needs AI analysis
  }
  
  return text.length < 30 ? 'low' : 'unknown';
}

// Claude priority analysis
async function analyzeMessagePriority(text: string): Promise<Priority> {
  const prompt = `
Analyze this message and determine its priority level.

Message: "${text}"

Respond with JSON:
{ "priority": "high" | "medium" | "low", "reason": "brief explanation" }

Priority guidelines:
- HIGH: Urgent matters, time-sensitive requests, emergencies, critical decisions
- MEDIUM: Important but not urgent, questions needing response, scheduled items
- LOW: Casual conversation, acknowledgments, social messages
`;
  
  const response = await anthropic.messages.create({
    model: "claude-sonnet-4-20250514",
    max_tokens: 150,
    messages: [{ role: "user", content: prompt }]
  });
  
  const result = JSON.parse(response.content[0].text);
  return result.priority;
}
```

**Performance Targets:**
- Quick heuristic: <10ms
- AI analysis: <500ms
- False positive rate (marking non-urgent as urgent): <15%
- API cost: <$0.001 per message analyzed

**Priority Indicators:**
- **High Priority:** Urgent keywords, deadlines, questions requiring immediate response, emergencies
- **Medium Priority:** Requests for action, questions, meeting scheduling, decisions needed
- **Low Priority:** Acknowledgments, casual chat, emoji-only messages, greetings

---

### Feature 5: Decision Tracking

**User Story:**  
*"As a user in group chats, I want to track important decisions that were made, so everyone stays aligned and I can reference them later."*

**Functionality:**
- Identify when a decision has been made in conversation
- Extract the decision and supporting context
- Track who participated in the decision
- Show timeline of decisions for the conversation

**UI/UX:**
- **Entry Point:** "Decisions" tab in conversation details
- **Loading State:** "Scanning for decisions..."
- **Display:** Timeline view with:
  - Decision text (bold)
  - Context paragraph
  - Participants involved
  - Date decided
  - Link to source messages
  - "Add Comment" option

**Technical Implementation:**

*Cloud Function: `trackDecisions`*

```typescript
interface DecisionRequest {
  conversationId: string;
  userId: string;
  messageRange?: { start: timestamp, end: timestamp };
}

// Processing flow
1. Validate user access
2. Query messages (last 100 by default, or specified range)
3. Check for cached decisions (< 24 hours old)
4. Send to Claude with decision extraction prompt
5. Store in /ai_decisions subcollection
6. Return decisions to client

// Claude prompt
const prompt = `
Identify decisions made in this group conversation. A decision is when participants agree on a course of action, choice, or resolution.

Conversation participants: ${participantNames}
Messages:
${formattedMessages}

Return JSON array:
[
  {
    "decision": "Clear statement of what was decided",
    "context": "2-3 sentence context explaining why/how",
    "participantIds": ["uid1", "uid2"],  // Who agreed or participated
    "sourceMessageIds": ["msgId1", "msgId2"],  // Messages showing the decision
    "confidence": 0.0-1.0  // How confident you are this is a decision
  }
]

Only include decisions with confidence > 0.7.
Examples of decisions:
- "We'll launch the feature next Tuesday"
- "John will be the point person for this project"
- "Budget approved at $50k"
- "Meeting rescheduled to 3pm Friday"
`;
```

**Performance Targets:**
- Response time: 3-4 seconds for 100 messages
- Accuracy: >75% precision on identifying real decisions
- False positive rate: <25%

---

## Implementation Details

### Development Phases

**Phase 1: Infrastructure Setup (Week 1)**
- Set up Firebase Cloud Functions project
- Install Vercel AI SDK and Anthropic SDK
- Set up Pinecone account and index
- Configure environment variables and secrets
- Create Firestore security rules for new AI collections

**Phase 2: Embedding Pipeline (Week 1-2)**
- Implement `embedMessage` Cloud Function with Firestore trigger
- Test embedding generation and Pinecone storage
- Backfill embeddings for existing messages (batch job)
- Monitor embedding costs and performance

**Phase 3: Core AI Features (Week 2-4)**
- Implement Thread Summarization
- Implement Action Item Extraction
- Implement Smart Search
- Implement Priority Message Detection
- Implement Decision Tracking

**Phase 4: Frontend Integration (Week 3-5)**
- Create UI components for all features
- Implement loading states and error handling
- Add feature entry points to existing screens
- Test on iOS and Android

**Phase 5: Testing & Optimization (Week 5-6)**
- End-to-end testing of all features
- Performance optimization
- Cost analysis and optimization
- User acceptance testing
- Bug fixes and refinements

### Firebase Cloud Functions Structure

```
functions/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ summarization.ts      # Thread summarization logic
â”‚   â”‚   â”œâ”€â”€ actionItems.ts        # Action item extraction
â”‚   â”‚   â”œâ”€â”€ search.ts             # Semantic search
â”‚   â”‚   â”œâ”€â”€ priority.ts           # Priority detection
â”‚   â”‚   â”œâ”€â”€ decisions.ts          # Decision tracking
â”‚   â”‚   â””â”€â”€ embeddings.ts         # Embedding generation
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ anthropic.ts          # Claude API client
â”‚   â”‚   â”œâ”€â”€ pinecone.ts           # Pinecone client
â”‚   â”‚   â”œâ”€â”€ openai.ts             # OpenAI embeddings client
â”‚   â”‚   â”œâ”€â”€ validation.ts         # Request validation
â”‚   â”‚   â””â”€â”€ security.ts           # Permission checks
â”‚   â””â”€â”€ index.ts                  # Function exports
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

### Environment Variables

```bash
# Anthropic API
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI API (for embeddings)
OPENAI_API_KEY=sk-...

# Pinecone
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=message-ai-embeddings

# Feature flags
ENABLE_PRIORITY_DETECTION=true
ENABLE_REAL_TIME_EMBEDDING=true
```

### Cost Estimation

**Per-User Monthly Costs (Assumptions: 500 messages/month):**

| Feature | API Calls | Unit Cost | Monthly Cost |
|---------|-----------|-----------|--------------|
| Message Embeddings | 500 | $0.0001 | $0.05 |
| Thread Summaries (5/month) | 5 | $0.05 | $0.25 |
| Action Items (10/month) | 10 | $0.02 | $0.20 |
| Smart Search (20/month) | 20 | $0.01 | $0.20 |
| Priority Detection (50/month) | 50 | $0.001 | $0.05 |
| Decisions (5/month) | 5 | $0.03 | $0.15 |
| **Total** | | | **$0.90** |

**Pinecone Costs:**
- Starter plan: $70/month (1M vectors, sufficient for MVP)
- Scales with user base

**Firebase Costs:**
- Cloud Functions: Pay-as-you-go (~$10-50/month for MVP scale)
- Firestore: Minimal (existing usage + AI metadata)

---

## Performance Requirements

### Response Time Targets

| Feature | Target | Maximum Acceptable |
|---------|--------|-------------------|
| Thread Summarization (100 msgs) | 3-5s | 8s |
| Action Item Extraction | 2-4s | 6s |
| Smart Search | <800ms | 1.5s |
| Priority Detection | <500ms | 1s |
| Decision Tracking | 3-4s | 7s |
| Message Embedding | <200ms | 500ms |

### Scalability Targets

- **Concurrent Users:** Support 1,000 concurrent users initially
- **Messages per Second:** Handle 100 messages/second embedding pipeline
- **Search Queries:** Support 50 queries/second
- **API Rate Limits:** Respect Anthropic rate limits (50 requests/minute on starter tier)

### Reliability Targets

- **Uptime:** 99.5% (excluding scheduled maintenance)
- **Error Rate:** <2% for AI feature requests
- **Cache Hit Rate:** >50% for summaries and action items

---

## Security & Privacy

### Data Security

**Principle: AI features respect existing conversation permissions**

1. **Authentication Required:** All AI feature requests require valid Firebase Auth token
2. **Authorization Checks:** Verify user is in conversation's `participants` array before processing
3. **Data Isolation:** Users can only access AI features for their own conversations
4. **Embedding Security:** Pinecone queries filtered by `participants` array

### Firestore Security Rules

```javascript
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    
    // AI summaries - only conversation participants can access
    match /conversations/{conversationId}/ai_summaries/{summaryId} {
      allow read: if request.auth != null && 
        request.auth.uid in get(/databases/$(database)/documents/conversations/$(conversationId)).data.participants;
      allow write: if false;  // Only Cloud Functions can write
    }
    
    // AI action items
    match /conversations/{conversationId}/ai_action_items/{itemId} {
      allow read: if request.auth != null && 
        request.auth.uid in get(/databases/$(database)/documents/conversations/$(conversationId)).data.participants;
      allow update: if request.auth != null && 
        request.auth.uid in get(/databases/$(database)/documents/conversations/$(conversationId)).data.participants &&
        request.resource.data.diff(resource.data).affectedKeys().hasOnly(['status', 'completedAt']);
      allow create, delete: if false;  // Only Cloud Functions
    }
    
    // AI decisions
    match /conversations/{conversationId}/ai_decisions/{decisionId} {
      allow read: if request.auth != null && 
        request.auth.uid in get(/databases/$(database)/documents/conversations/$(conversationId)).data.participants;
      allow write: if false;  // Only Cloud Functions can write
    }
    
    // Message embeddings metadata (Pinecone is source of truth)
    match /message_embeddings/{messageId} {
      allow read: if false;  // Only used by Cloud Functions
      allow write: if false;  // Only Cloud Functions
    }
  }
}
```

### Privacy Considerations

1. **Data Retention:** 
   - AI summaries cached for 1 hour
   - Action items persist until conversation is deleted
   - Embeddings in Pinecone persist for search functionality
   - Users can request data deletion (delete conversation deletes all AI data)

2. **Third-Party Data Sharing:**
   - Message content sent to Anthropic for processing (covered by their privacy policy)
   - Embeddings stored in Pinecone (covered by their privacy policy)
   - No data sold to third parties
   - All processing happens server-side (no AI SDKs in mobile app)

3. **Anonymization:**
   - User IDs (UIDs) used for authorization but not sent to AI models
   - Display names sent to AI for context (necessary for accurate summaries)

---

## Testing Strategy

### Unit Testing

**Cloud Functions:**
- Test each AI feature function independently
- Mock Anthropic/OpenAI API responses
- Test error handling and edge cases
- Test security rules and authorization

**Frontend Components:**
- Test loading states
- Test error states
- Test data display
- Test user interactions

### Integration Testing

**End-to-End Flows:**
1. User requests thread summary â†’ Summary generated and displayed
2. Message sent â†’ Embedded â†’ Searchable via Smart Search
3. Action item extracted â†’ Displayed in UI â†’ Marked complete
4. Priority message sent â†’ Detected â†’ Push notification sent
5. Decision made â†’ Tracked â†’ Displayed in timeline

**Performance Testing:**
- Load test embedding pipeline with 100 messages/second
- Load test search with 50 concurrent queries
- Measure response times for all features
- Test with various conversation sizes (10, 100, 1000+ messages)

### User Acceptance Testing

**Test Scenarios:**
1. **Thread Summarization:**
   - Summarize a 50-message work conversation
   - Summarize a 100-message group chat
   - Verify key points accuracy
   - Test with different conversation types (1-on-1, group, work, casual)

2. **Action Item Extraction:**
   - Create conversation with clear action items
   - Create conversation with ambiguous tasks
   - Test assignee and due date extraction
   - Mark items as complete and verify state

3. **Smart Search:**
   - Search for specific message by keyword
   - Search by concept (e.g., "budget discussion")
   - Search across multiple conversations
   - Verify results relevance

4. **Priority Detection:**
   - Send urgent message with "URGENT" keyword
   - Send casual message
   - Verify priority badges appear correctly
   - Test push notification enhancement

5. **Decision Tracking:**
   - Have group conversation with clear decision
   - Verify decision extracted correctly
   - Check decision timeline display
   - Test with multiple decisions

### Quality Metrics

**Accuracy Targets:**
- Thread Summaries: >90% user satisfaction ("accurate and helpful")
- Action Items: >85% precision, >80% recall
- Smart Search: >80% relevance for top result
- Priority Detection: >85% accuracy, <15% false positives
- Decision Tracking: >75% precision

**User Feedback Collection:**
- Thumbs up/down on summaries
- "Report incorrect action item" button
- Search result click-through rate
- Priority badge feedback ("mark as incorrect")
- Decision timeline feedback

---

## Success Metrics

### Primary Metrics

1. **Adoption Rate:**
   - **Target:** 60% of active users try at least one AI feature within first month
   - **Target:** 30% of active users use AI features weekly

2. **Feature Usage:**
   - Thread Summarization: 5+ uses per user per month
   - Smart Search: 20+ searches per user per month
   - Action Items: 70% of action items marked as "helpful"

3. **User Satisfaction:**
   - **Target:** >4.0/5.0 average rating for AI features
   - **Target:** <10% negative feedback rate

4. **Performance:**
   - **Target:** 95% of requests complete within target response times
   - **Target:** <2% error rate

### Secondary Metrics

1. **Cost Efficiency:**
   - **Target:** <$1.00 per user per month for AI features
   - **Target:** >50% cache hit rate for summaries

2. **Engagement Impact:**
   - **Hypothesis:** AI features increase daily active users by 10%
   - **Hypothesis:** Users spend 20% more time in app (reading summaries vs scrolling)

3. **Retention:**
   - **Hypothesis:** Users with AI feature usage have 15% higher 30-day retention

### Data Collection

**Analytics Events:**
```typescript
// Track AI feature usage
analytics.logEvent('ai_feature_used', {
  feature: 'thread_summarization',
  conversationId: string,
  messageCount: number,
  responsetime: number,
  cacheHit: boolean
});

analytics.logEvent('ai_feature_feedback', {
  feature: 'action_items',
  rating: 1-5,
  feedback: string  // optional
});
```

---

## Future Enhancements

### Phase 2: UX Improvements

**Progressive Search Results (4-6 hours implementation)**
- **Current:** All 10 results appear at once (~800ms)
- **Enhancement:** First result at ~500ms, remaining results load progressively
- **UX Benefit:** Feels 300ms faster, matches user expectations (Google-like)
- **Technical:** Return first result immediately, stream remaining results
- **Priority:** Medium (nice-to-have)

**Why NOT Streaming for Summarization:**
- Marginal UX benefit (users need complete summary to act)
- Possibly worse UX (distracting, hard to skim)
- Users expect to wait for complete summaries
- Not worth implementation time (4-6 hours)

### Phase 3: Advanced Features

**Multi-Language Support:**
- Detect message language automatically
- Support summarization and search in 10+ languages
- UI localization for AI feature screens

**Conversation Insights:**
- Analytics dashboard for group chats
- Activity patterns (who talks most, response times)
- Topic trends over time
- Sentiment analysis

**Smart Replies:**
- AI-suggested responses based on conversation context
- Quick reply options for common scenarios
- Context-aware suggestions

**Meeting Coordination:**
- Automatic meeting scheduling from group chat
- Extract meeting times and participants
- Calendar integration
- Meeting agenda generation from discussion

### Phase 4: Integration & Automation

**Voice Message Transcription:**
- Real-time transcription of voice messages
- Make voice content searchable
- Accessibility improvement

**File Analysis:**
- Extract text from images and documents
- Summarize shared files
- Make file contents searchable

**Automated Workflows:**
- "When someone mentions deadline, create calendar event"
- "When action item assigned to me, add to to-do list"
- "When decision made, post summary to specific channel"

**Third-Party Integrations:**
- Slack/Discord export
- Google Calendar sync for action items
- Notion/Trello integration for task management

---

## Appendix

### Glossary

- **RAG (Retrieval-Augmented Generation):** AI technique combining document retrieval with language model generation
- **Embedding:** Numerical vector representation of text for semantic similarity comparison
- **Semantic Search:** Search based on meaning rather than exact keyword matching
- **Vector Database:** Specialized database for storing and querying embeddings
- **Context Window:** Maximum amount of text an AI model can process at once
- **LLM (Large Language Model):** AI model trained on text data (e.g., Claude, GPT)
- **Cloud Function:** Serverless function that runs in response to events
- **Subcollection:** Nested collection within a Firestore document

### References

- **Anthropic Claude Documentation:** https://docs.anthropic.com
- **Vercel AI SDK Documentation:** https://sdk.vercel.ai/docs
- **Pinecone Documentation:** https://docs.pinecone.io
- **Firebase Cloud Functions:** https://firebase.google.com/docs/functions
- **OpenAI Embeddings:** https://platform.openai.com/docs/guides/embeddings

### Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | Oct 22, 2025 | Product Team | Initial MVP specification |

---

**Document Status:** âœ… Ready for Implementation  
**Next Steps:** Begin Phase 1 infrastructure setup  
**Questions?** Contact product team

---

*This PRD is a living document and will be updated as requirements evolve and implementation insights are gained.*